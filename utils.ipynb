{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad00616-d9d2-40cd-8c9b-c9b61f1056ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from keras.api.keras.utils import to_categorical\n",
    "from keras.api.keras.models import Sequential, Model\n",
    "from keras.api.keras.layers import Input, Dense, Conv2D, MaxPool2D , Flatten, MaxPooling2D, BatchNormalization, Activation, Add, ReLU, SeparableConv2D, GlobalAvgPool2D, Dropout, add, GlobalAveragePooling2D\n",
    "from keras.api.keras.utils import plot_model\n",
    "from keras.api.keras.optimizers import SGD, Adam\n",
    "from keras.api.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from keras.api.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beddcc5-53fe-488d-aee1-a2a78e88134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_labels = ['D2', 'D21', 'D36', 'D4', 'D46', 'D58', 'E23', 'E34', 'F31', 'F35', 'G1', 'G17',\n",
    "                  'G43', 'I10', 'I9', 'M17', 'M23', 'N35', 'O1', 'O34', 'O4', 'O49', 'Q1', 'Q3',\n",
    "                  'R4', 'R8', 'S29', 'S34', 'U7', 'V13', 'V28', 'V30', 'V31', 'W11', 'W24', 'X1',\n",
    "                  'X8', 'Y1', 'Y5', 'Z1']\n",
    "\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "label_enc.fit(allowed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7f522-a4ae-4bf4-9a62-169207587b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extra_dim(imgs, labels, n_classes):\n",
    "    if imgs.ndim == 3:\n",
    "        imgs = imgs.reshape((imgs.shape[0], imgs.shape[1], imgs.shape[2], 1))\n",
    "    else:\n",
    "        print(\"error: imgs dataset dimension is \" +str(imgs.ndim)+\" instead 3\")\n",
    "        return\n",
    "    if labels.ndim == 1:\n",
    "        labels = to_categorical(labels, num_classes=n_classes)\n",
    "    else:\n",
    "        print(\"error: labels dataset dimension is \" +str(labels.ndim)+\" instead 1\")\n",
    "        return\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f5d08-6f5f-40e7-bbe5-dd9c3991b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filelist(path, file_extension):\n",
    "    filelist = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if(file.endswith(\".\" + file_extension)):\n",
    "                #append the file name to the list\n",
    "                filelist.append(os.path.join(root,file))\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab90af-033d-4ea8-9400-9d5e56203769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, file_extension):\n",
    "    filelist = create_filelist(path, file_extension)\n",
    "    X, y = [], []\n",
    "    for file in filelist:\n",
    "        img = cv2.imread(file, 0) # opens the image in grayscale\n",
    "        X.append(img)\n",
    "        y.append(path_to_label(file)) # gets the label from the filename\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c95775-8a27-4912-a80a-87a74180c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_number_in_category(labels, label_enc=None, view=False, sort=True):\n",
    "    if labels.ndim == 2:\n",
    "        labels = categorical_to_decoded(labels, label_enc)\n",
    "        all_labels = label_enc.classes_\n",
    "    else:\n",
    "        all_labels = list(set(labels))\n",
    "    dict_labels = dict.fromkeys(set(all_labels), 0) \n",
    "    for l in labels:\n",
    "        dict_labels[l] = dict_labels[l] + 1\n",
    "    #sorted\n",
    "    if sort == True:\n",
    "        sorted_dict = {}\n",
    "        sorted_keys = sorted(dict_labels, key=dict_labels.get, reverse=True) \n",
    "        for w in sorted_keys:\n",
    "            sorted_dict[w] = dict_labels[w]\n",
    "        dict_labels = sorted_dict\n",
    "    #view  \n",
    "    if view == True:\n",
    "        for k, v in dict_labels.items():\n",
    "            print(k, v)\n",
    "        print(\"tot labels number: \" + str(len(dict_labels)))\n",
    "    return dict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002eaad-a24d-4242-88be-3dce20f7770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_data(predictions, X_test, y_test, label_enc, summary=False, details=False, \n",
    "                        plot=(None,0,None), y_train=None):\n",
    "    print(f'Test dataset dimensions: {X_test.shape}')\n",
    "    # plot = (plot_type, plot_n, only_label_to_print)\n",
    "    # plot_type  0 - only corrected pred\n",
    "    #            1 - only wrong pred\n",
    "    #            2 - corrected + wrong pred\n",
    "    #            None\n",
    "    # plot_n     int - number of images to plot\n",
    "    #            \"all\" plot all images\n",
    "    # only_label_to_print     \"S29\" - label of images to plot\n",
    "    #            None\n",
    "    if plot[0] is not None:\n",
    "        plot_type = plot[0]\n",
    "    else:\n",
    "        plot_type = None\n",
    "    plot_n = plot[1]\n",
    "    only_label_to_print = plot[2]\n",
    "    pred_corr = 0\n",
    "    pred_wrong = 0\n",
    "    plot_counter = 0\n",
    "    y_test_decoded = label_enc.inverse_transform(np.argmax(y_test, axis=1))\n",
    "    d_pred_corr = dict.fromkeys(set(y_test_decoded), 0)\n",
    "    d_tot_label = dict.fromkeys(set(y_test_decoded), 0)\n",
    "    if y_train is not None:\n",
    "        d_train_label = get_labels_number_in_category(y_train, label_enc)\n",
    "        \n",
    "    for i,prediction in enumerate(predictions):\n",
    "        p = np.argmax(prediction)\n",
    "        true_label_enc = np.argmax(y_test[i])\n",
    "        true_label = label_enc.inverse_transform([true_label_enc])[0]\n",
    "        d_tot_label[true_label] = d_tot_label[true_label] +1\n",
    "        \n",
    "        if plot_n == \"all\":\n",
    "            plot_n = len(predictions)\n",
    "        \n",
    "        if p == true_label_enc:\n",
    "            pred_corr = pred_corr + 1\n",
    "            d_pred_corr[true_label] = d_pred_corr[true_label] +1\n",
    "            if(summary is True):\n",
    "                print(\"test \" + str(i+1)+\"/\"+str(len(predictions)) + \" corrected prediction  \" + \"prediction = \"+ str(p) +\"  true_label_enc = \"+ str(true_label_enc))\n",
    "            \n",
    "            if plot_type == 0 or plot_type == 2 :  \n",
    "                if plot_counter < plot_n:\n",
    "                    if only_label_to_print is not None:\n",
    "                        if str(true_label) == only_label_to_print:\n",
    "                            plt.figure(i)\n",
    "                            plt.imshow(X_test[i], cmap=\"gray\")\n",
    "                            plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_corr)+\"째 corrected - \" +\"label \"+ str(true_label))\n",
    "                            plot_counter = plot_counter + 1\n",
    "                    else:        \n",
    "                        plt.figure(i)\n",
    "                        plt.imshow(X_test[i], cmap=\"gray\")\n",
    "                        plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_corr)+\"째 corrected - \" +\"label \"+ str(true_label))\n",
    "                        plot_counter = plot_counter + 1\n",
    "                    \n",
    "        else:\n",
    "            pred_wrong = pred_wrong + 1\n",
    "            if summary is True:\n",
    "                print(\"test \" + str(i+1)+\"/\"+str(len(predictions)) + \" wrong prediction\")\n",
    "            if plot_type == 1 or plot_type == 2:\n",
    "                if plot_counter < plot_n:   \n",
    "                    if only_label_to_print is not None:\n",
    "                        if str(true_label) == only_label_to_print:\n",
    "                            plt.figure(i)\n",
    "                            plt.imshow(X_test[i], cmap=\"gray\")\n",
    "                            plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_wrong)+\"째 wrong prediction - \" +\"true_label:\" +str(true_label)+ \" - pred_label:\" +str(label_enc.inverse_transform([p])[0]))\n",
    "                            plot_counter = plot_counter + 1\n",
    "                    else:\n",
    "                        plt.figure(i)\n",
    "                        print(X_test[i].shape)\n",
    "                        plt.imshow(X_test[i], cmap=\"gray\")\n",
    "                        plt.title(\"test \"+str(i+1)+\"/\"+str(len(predictions))+\" - \"+str(pred_wrong)+\"째 wrong prediction - \" +\"true_label:\" +str(true_label)+ \" - pred_label:\" +str(label_enc.inverse_transform([p])[0]))\n",
    "                        plot_counter = plot_counter + 1\n",
    "    \n",
    "    if summary is True:\n",
    "        print(\"-------\")\n",
    "        print(\"Corrected predictions: \" + str(pred_corr) + \"/\" + str(len(predictions)) )\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    if details is True:\n",
    "        if y_train is None:\n",
    "            for key in d_tot_label:\n",
    "                print(str(round(d_pred_corr[key]/d_tot_label[key]*100)) +\"% \"+ str(d_pred_corr[key])+\"/\"+str(d_tot_label[key]) +\" \"+ key )\n",
    "        else:\n",
    "            for key in d_train_label:\n",
    "                if key in d_tot_label:\n",
    "                    print(str(d_train_label[key]) + \" \"+ str(round(d_pred_corr[key]/d_tot_label[key]*100)) +\"% \"+ str(d_pred_corr[key])+\"/\"+str(d_tot_label[key]) +\" \"+ key )    \n",
    "                else:\n",
    "                    print(str(d_train_label[key]) + \" No images in test of label \"+ str(key))\n",
    "        print(\"-------\")\n",
    "        print(\"Correct prediction: \" +str(sum(d_pred_corr.values()))+\"/\"+str(sum(d_tot_label.values())))\n",
    "  \n",
    "    if plot_type == 0 or plot_type == 1 or plot_type == 2 :\n",
    "        plt.show()\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60870a7-20dc-4457-840c-efbecf0ce283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_label(path):\n",
    "    # the filename format is yourfilename_LABEL.format, the LABEL is the gardiner code\n",
    "    # and should be one of the allowed_labels listed above (case sensitive)\n",
    "    file_name_parts = path.split('/')\n",
    "    img_name = file_name_parts[-1]\n",
    "    img_name_parts = img_name.split('_')\n",
    "    lable = img_name_parts[-1].split('.')[0]\n",
    "    return lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba2d87-c249-44ee-8cbd-04ddc5a09c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = ATCNet(shape=(100, 100, 1), n_classes=n_classes)\n",
    "\n",
    "    top3 = tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top3\")\n",
    "    top5 = tf.keras.metrics.TopKCategoricalAccuracy(k=5, name=\"top5\")\n",
    "    model.compile(optimizer=Adam(), \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy', top3, top5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f62a9-9036-404a-8fe9-b639a1365d74",
   "metadata": {
    "id": "C4lvfUpNQ3Zh"
   },
   "outputs": [],
   "source": [
    "def ATCNet(shape, n_classes):  \n",
    "\n",
    "    # INPUT BLOCK\n",
    "\n",
    "    input = Input(shape=shape)\n",
    "    x = Conv2D(64, (3, 3), padding='same', use_bias=False, name='input_block_conv1')(input)\n",
    "    x = BatchNormalization(name='input_block_conv1_bn')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2,2), padding=\"same\", name = \"input_block_conv1_pool\")(x)  \n",
    "    x = Activation('relu', name='input_block_conv1_act')(x)  \n",
    "    x = Conv2D(64, (3, 3), padding='same', use_bias=False, name='input_block_conv2')(x)\n",
    "    x = BatchNormalization(name='input_block_conv2_bn')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2,2), padding=\"same\", name = \"input_block_conv2_pool\")(x)  \n",
    "    x = Activation('relu', name='input_block_conv2_act')(x)\n",
    "\n",
    "\n",
    "    # MIDDLE BLOCKS\n",
    "\n",
    "    # MIDDLE BLOCK 1\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='middle_block1_sepconv1')(x)\n",
    "    x = BatchNormalization(name='middle_block1_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='middle_block1_sepconv1_act')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='middle_block1_sepconv2')(x)\n",
    "    x = BatchNormalization(name='middle_block1_sepconv2_bn')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2,2), padding=\"same\", name='middle_block1_sepconv2_pool')(x)\n",
    "    x = Activation('relu', name='middle_block1_sepconv2_act')(x)\n",
    "\n",
    "    # MIDDLE BLOCK 2\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='middle_block2_sepconv1')(x)\n",
    "    x = BatchNormalization(name='middle_block2_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='middle_block2_sepconv1_act')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='middle_block2_sepconv2')(x)\n",
    "    x = BatchNormalization(name='middle_block2_sepconv2_bn')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2,2), padding=\"same\", name='middle_block2_sepconv2_pool')(x)\n",
    "    x = Activation('relu', name='middle_block2_sepconv2_act')(x)\n",
    "\n",
    "    # MIDDLE BLOCK 3\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='middle_block3_sepconv1')(x)\n",
    "    x = BatchNormalization(name='middle_block3_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='middle_block3_sepconv1_act')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='middle_block3_sepconv2')(x)\n",
    "    x = BatchNormalization(name='middle_block3_sepconv2_bn')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2,2), padding=\"same\", name='middle_block3_sepconv2_pool')(x)\n",
    "    x = Activation('relu', name='middle_block3_sepconv2_act')(x)\n",
    "\n",
    "    # MIDDLE BLOCK 4\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='middle_block4_sepconv1')(x)\n",
    "    x = BatchNormalization(name='middle_block4_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='middle_block4_sepconv1_act')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='middle_block4_sepconv2')(x)\n",
    "    x = BatchNormalization(name='middle_block4_sepconv2_bn')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2,2), padding=\"same\", name='middle_block4_sepconv2_pool')(x)\n",
    "    x = Activation('relu', name='middle_block4_sepconv2_act')(x)\n",
    "\n",
    "    # EXIT BLOCK \n",
    "    x = SeparableConv2D(512, (3, 3), padding='same', use_bias=False, name='exit_block_sepconv')(x)\n",
    "    x = BatchNormalization(name='exit_block_sepconv_bn')(x)\n",
    "    x = Activation('relu', name='exit_block_sepconv_act')(x)\n",
    "\n",
    "    # TOP\n",
    "    x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "    x = Dropout(0.15, name=\"dropout\")(x)\n",
    "    output = Dense(n_classes, activation='softmax', name='predictions', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    #output = Dense(n_classes, activation='softmax', name='predictions')(x)\n",
    "    model = Model(input, output, name=\"ATCNet\")\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
